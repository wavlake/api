# Cloud Build configuration for API service
# Used for both manual deployments and automated CI/CD

steps:
  # Step 1: Build the Docker image
  - name: 'gcr.io/cloud-builders/docker'
    args: [
      'build',
      '-t', '${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPOSITORY}/api:${_IMAGE_TAG}',
      '-t', '${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPOSITORY}/api:latest',
      '--build-arg', 'COMMIT_SHA=${_IMAGE_TAG}',
      '--cache-from', '${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPOSITORY}/api:latest',
      '.'
    ]

  # Step 2: Push the Docker image to Artifact Registry
  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', '--all-tags', '${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPOSITORY}/api']

  # Step 3: Deploy to Cloud Run with S3 support
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: gcloud
    args: [
      'run', 'deploy', 'api',
      '--image', '${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPOSITORY}/api:${_IMAGE_TAG}',
      '--region', '${_REGION}',
      '--platform', 'managed',
      '--allow-unauthenticated',
      # Environment variables - supports both GCS and S3
      '--set-env-vars', 'COMMIT_SHA=${_IMAGE_TAG},GOOGLE_CLOUD_PROJECT=$PROJECT_ID,STORAGE_PROVIDER=${_STORAGE_PROVIDER},GCS_BUCKET_NAME=${_GCS_BUCKET},AWS_REGION=us-east-2,AWS_S3_BUCKET_NAME=${_S3_BUCKET},AWS_S3_RAW_PREFIX=raw,AWS_S3_TRACK_PREFIX=track,AWS_S3_IMAGE_PREFIX=image,TEMP_DIR=/tmp',
      # Secrets - includes both existing and new AWS secrets
      '--update-secrets', 'WEBHOOK_SECRET=webhook-secret:latest,PROD_POSTGRES_CONNECTION_STRING_RO=PROD_POSTGRES_CONNECTION_STRING_RO:latest,AWS_ACCESS_KEY_ID=aws-access-key-id:latest,AWS_SECRET_ACCESS_KEY=${_AWS_SECRET}:latest',
      '--vpc-connector', '${_VPC_CONNECTOR}',
      '--service-account', '${_SERVICE_ACCOUNT}',
      '--min-instances', '${_MIN_INSTANCES}',
      '--max-instances', '${_MAX_INSTANCES}',
      '--memory', '${_MEMORY}',
      '--cpu', '${_CPU}',
      '--timeout', '${_TIMEOUT}',
      '--concurrency', '${_CONCURRENCY}'
    ]

  # Step 4: Run smoke tests
  - name: 'gcr.io/cloud-builders/gcloud'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        SERVICE_URL=$(gcloud run services describe api --platform managed --region ${_REGION} --format 'value(status.url)')
        echo "Testing service at: $${SERVICE_URL}"
        curl -f "$${SERVICE_URL}/heartbeat" || exit 1
        echo "Smoke test passed!"

# Substitution variables with defaults
substitutions:
  # Existing configuration (unchanged)
  _REGION: us-central1
  _REPOSITORY: api-repo
  _SERVICE_ACCOUNT: api-service@wavlake-alpha.iam.gserviceaccount.com
  _VPC_CONNECTOR: cloud-sql-postgres
  _IMAGE_TAG: 'manual-build'
  _MIN_INSTANCES: '0'
  _MAX_INSTANCES: '10'
  _MEMORY: '1Gi'
  _CPU: '1'
  _TIMEOUT: '300s'
  _CONCURRENCY: '80'
  
  # Storage configuration - choose storage provider
  _STORAGE_PROVIDER: gcs  # Change to 's3' for S3 migration
  
  # GCS configuration (existing)
  _GCS_BUCKET: wavlake-audio
  
  # S3 configuration (new)
  _S3_BUCKET: staging-wavlake-media  # or wavlake-media for production
  _AWS_SECRET: AWS_S3_MEDIA_SECRET_STAGING  # or AWS_S3_MEDIA_SECRET_PROD for production

# Build configuration options
options:
  logging: CLOUD_LOGGING_ONLY
  machineType: 'N1_HIGHCPU_8'
  substitutionOption: 'ALLOW_LOOSE'

# Build timeout (45 minutes)
timeout: '2700s'

# Tags for organizing builds
tags:
  - 'api'
  - 'production'
  - '$BRANCH_NAME'